{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10f93ef2cec1444fbb097160acc47e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20b0e57c2c364a0b947fadf31e61a479",
              "IPY_MODEL_ae0d18afc3094c4495be7b747daa04cf",
              "IPY_MODEL_3046bff62fbe414ebe1dd0531d0f33f2"
            ],
            "layout": "IPY_MODEL_72441bd05477491d8bd6d140b648bc31"
          }
        },
        "20b0e57c2c364a0b947fadf31e61a479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83bda3bd0f4144e6a9048b9b329fcd9e",
            "placeholder": "​",
            "style": "IPY_MODEL_33aa95eab8b444648b18c733371ddafa",
            "value": "Processing MIDI files: 100%"
          }
        },
        "ae0d18afc3094c4495be7b747daa04cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b7e64c4fa4c4aafb53f1f81f5e6bf35",
            "max": 499,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ab00dc71a9344418c54d3d90abf2942",
            "value": 499
          }
        },
        "3046bff62fbe414ebe1dd0531d0f33f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b25a1ab16af4a919f62a7ab9b74558e",
            "placeholder": "​",
            "style": "IPY_MODEL_052765d9ddb94f489370819529c82a1c",
            "value": " 499/499 [01:02&lt;00:00, 17.06it/s]"
          }
        },
        "72441bd05477491d8bd6d140b648bc31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83bda3bd0f4144e6a9048b9b329fcd9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33aa95eab8b444648b18c733371ddafa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b7e64c4fa4c4aafb53f1f81f5e6bf35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab00dc71a9344418c54d3d90abf2942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b25a1ab16af4a919f62a7ab9b74558e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "052765d9ddb94f489370819529c82a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Final Team Project: Music Genre and Composer Classification Using Deep Learning\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Music is a ubiquitous art form with a rich history. Different composers have imbued their work with unique styles, making identifying the creator of a piece challenging for novices. This project leverages deep learning to accurately identify the composer of a given musical score.\n",
        "\n",
        "### Objective\n",
        "\n",
        "The primary objective is developing a deep learning model to predict the composer of a musical score. We will utilize two techniques:\n",
        "\n",
        "- Long Short-Term Memory (LSTM)\n",
        "- Convolutional Neural Network (CNN)\n",
        "\n",
        "### Project Timeline\n",
        "\n",
        "- **Module 2 (End of Week 2):** Team formation (2-3 members). Utilize Canvas, USD Email, or Slack.\n",
        "- **Module 4 (End of Week 4):** Team representative submits \"Team Project Status Update Form.\"\n",
        "- **Module 7 (End of Week 7):** Final project deliverables due. **No extensions will be granted.**\n",
        "    - Project Report (PDF)\n",
        "    - Project Notebook (.ipynb exported as PDF or HTML)\n",
        "\n",
        "### Dataset\n",
        "\n",
        "The project utilizes a [Kaggle dataset](link_to_dataset) of MIDI files from classical composers.  Focus will be on:\n",
        "\n",
        "1. Bach\n",
        "2. Beethoven\n",
        "3. Chopin\n",
        "4. Mozart\n",
        "\n",
        "### Methodology\n",
        "\n",
        "1. **Data Collection:** Dataset provided.\n",
        "2. **Data Pre-processing:**  Convert scores to MIDI format and apply data augmentation.\n",
        "3. **Feature Extraction:**  Extract features like notes, chords, and tempo using music analysis tools.\n",
        "4. **Model Building:** Develop LSTM and CNN models for composer classification.\n",
        "5. **Model Training:** Train models using pre-processed and feature-extracted data.\n",
        "6. **Model Evaluation:** Evaluate performance using accuracy, precision, and recall metrics.\n",
        "7. **Model Optimization:** Fine-tune hyperparameters for optimal performance.\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "1. **Project Report (PDF):** Comprehensive documentation in APA 7 style ([Sample Professional Paper](link_to_sample)).  \n",
        "    - File Naming: `DeliverableName-TeamNumber.pdf` (e.g., `Project_Report-Team1.pdf`)\n",
        "    - Include:\n",
        "        - Methodology\n",
        "        - Data pre-processing steps\n",
        "        - Feature extraction techniques\n",
        "        - Model architecture\n",
        "        - Training process\n",
        "        - Reference list with citations\n",
        "        - Concluding section with findings and future improvements\n",
        "2. **Project Notebook (PDF or HTML):** Jupyter Notebook containing the complete project code.\n",
        "    - Data pre-processing\n",
        "    - Feature extraction\n",
        "    - Model building\n",
        "    - Training\n",
        "    - Evaluation\n",
        "    - Additional analysis/visualizations\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "This project aims to accurately predict composers of musical scores using LSTM and CNN models. The final model can benefit musicians, enthusiasts, and listeners alike.\n",
        "\n",
        "### Power Usage\n",
        "\n",
        "- Utilize Google Colab GPU/TPU for increased computational power.\n",
        "- Consider subscribing to [Google Colab Pro+](https://colab.research.google.com/signup) if needed.\n",
        "\n",
        "**Note:** Team member grades may vary based on individual contribution levels.\n",
        "\n",
        "This assignment uses **Turnitin** for plagiarism detection. Review your work using the **Draft Coach** extension in Google Docs before submission.\n",
        "\n",
        "### Rubric\n",
        "\n",
        "#### Final Team Project Scoring Rubric\n",
        "\n",
        "| Criteria | Ratings | Pts |\n",
        "|---|---|---|\n",
        "| **Project Report (25%)** | Meets or Exceeds Expectations: Report thoroughly describes methodology, data preprocessing, feature extraction, model architecture, and training process for reproducibility. | 75 pts |\n",
        "|  | Approaches Expectations: Report generally describes the above, but needs minor revisions. | 61.5 pts |\n",
        "|  | Below Expectations: Report minimally describes the above, requiring major revisions. | 52.5 pts |\n",
        "|  | Inadequate Attempt: Report misses one or more key elements. | 0 pts |\n",
        "|  | Non-Performance | 0 pts |\n",
        "| **Project Notebook (65%)** | Meets or Exceeds Expectations: High-quality notebook with complete code, including data preprocessing, feature extraction, model building, training, evaluation, and additional analysis. | 175.5 pts |\n",
        "|  | Approaches Expectations: Notebook contains all elements but needs minor revisions. | 159.9 pts |\n",
        "|  | Below Expectations: Notebook contains all elements but needs major revisions. | 136.5 pts |\n",
        "|  | Inadequate Attempt: Notebook missing one or more key elements. | 0 pts |\n",
        "|  | Non-Performance | 0 pts |\n",
        "| **References and Citations (5%)** | Meets or Exceeds Expectations: Complete reference list with proper APA citations. | 13.5 pts |\n",
        "|  | Approaches Expectations: Reference list needs minor APA formatting revisions. | 12.3 pts |\n",
        "|  | Below Expectations: Reference list needs major APA formatting revisions. | 10.5 pts |\n",
        "|  | Inadequate Attempt: Incomplete or missing reference list. | 0 pts |\n",
        "|  | Non-Performance | 0 pts |\n",
        "| **Conclusion (5%)** | Meets or Exceeds Expectations: Thorough conclusion summarizing the project, highlighting key findings, and suggesting future improvements. | 13.5 pts |\n",
        "|  | Approaches Expectations: Adequate conclusion, but could benefit from further elaboration. | 12.3 pts |\n",
        "|  | Below Expectations: Vague conclusion, lacking key elements. | 10.5 pts |\n",
        "|  | Inadequate Attempt: Conclusion missing one or more key elements. | 0 pts |\n",
        "|  | Non-Performance | 0 pts |\n",
        "| **Total Points:** | | **300** |\n"
      ],
      "metadata": {
        "id": "UvMYlQnDt_7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def bootstrap():\n",
        "    # @title Bootstrap Google Colab {display-mode:\"form\"}\n",
        "\n",
        "    # CONFIGURE: Parameters\n",
        "    GOOGLE_DRIVE_FOLDER = \"aai-511\" # @param {type:\"string\"}\n",
        "    GitHub = True  # @param {type:\"boolean\"}\n",
        "    OpenAI = True  # @param {type:\"boolean\"}\n",
        "    HuggingFace = True  # @param {type:\"boolean\"}\n",
        "    Kaggle = True  # @param {type:\"boolean\"}\n",
        "\n",
        "    # ENSURE: Secrets\n",
        "    from google.colab import userdata\n",
        "    SECRETS = [\n",
        "        (\"GH_TOKEN\", GitHub), # https://github.com/settings/personal-access-tokens/new\n",
        "        (\"GITHUB_USERNAME\", GitHub), # git config --global user.name\n",
        "        (\"GITHUB_EMAIL\", GitHub), # git config --global user.email\n",
        "        (\"OPENAI_API_KEY\", OpenAI), # https://platform.openai.com/api-keys\n",
        "        (\"HF_TOKEN\", HuggingFace), # https://huggingface.co/settings/tokens?new_token=true\n",
        "        (\"KAGGLE_USERNAME\", Kaggle),\n",
        "        (\"KAGGLE_KEY\", Kaggle), # https://www.kaggle.com/settings#:~:text=Create%20New%20Token\n",
        "    ]\n",
        "    for secret, enabled in SECRETS:\n",
        "        if enabled:\n",
        "            try:\n",
        "                userdata.get(secret)\n",
        "            except userdata.SecretNotFoundError:\n",
        "                raise ValueError(f\"Must set Google Colab secret: {secret}.\")\n",
        "\n",
        "    # CONFIGURE: Environment\n",
        "    import os\n",
        "    os.environ['PIP_QUIET'] = '3'\n",
        "    os.environ['PIP_PROGRESS_BAR'] = 'off'\n",
        "    os.environ['PIP_ROOT_USER_ACTION'] = 'ignore'\n",
        "    os.environ['DEBIAN_FRONTEND'] = 'noninteractive'\n",
        "\n",
        "    # CONFIGURE: matplotlib\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.rcParams['figure.dpi'] = 300\n",
        "    plt.rcParams['savefig.dpi'] = 300\n",
        "\n",
        "    # DISABLE: Telemetry\n",
        "    os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'\n",
        "    os.environ['GRADIO_ANALYTICS_ENABLED'] = 'False'\n",
        "\n",
        "    # CONFIGURE: apt\n",
        "    # https://manpages.ubuntu.com/manpages/bionic/man5/apt.conf.5.html\n",
        "    APT_CONFIG = [\n",
        "        'APT::Acquire::Retries \"20\";',\n",
        "        'APT::Clean-Installed \"true\";',\n",
        "        'APT::Get::Assume-Yes \"true\";',\n",
        "        'APT::Get::Clean \"always\";',\n",
        "        'APT::Get::Fix-Broken \"true\";',\n",
        "        'APT::Install-Recommends \"0\";',\n",
        "        'APT::Install-Suggests \"0\";',\n",
        "        'APT::Sources::List::Disable-Auto-Refresh \"true\";',\n",
        "        'Dpkg::Options \"--force-confnew\";',\n",
        "        'Dpkg::Use-Pty \"0\";',\n",
        "        'Quiet \"2\";',\n",
        "    ]\n",
        "    with open('/etc/apt/apt.conf.d/01apt.conf', 'w') as file:\n",
        "        for setting in APT_CONFIG:\n",
        "            file.write(setting + '\\n')\n",
        "\n",
        "    # INSTALL: uv\n",
        "    # https://github.com/astral-sh/uv\n",
        "    !pip install uv\n",
        "\n",
        "    # AUTHENTICATE: GitHub\n",
        "    # https://github.com/cli/cli/blob/trunk/docs/install_linux.md\n",
        "    if GitHub:\n",
        "        !apt-get remove --purge gh > /dev/null\n",
        "        !mkdir -p -m 755 /etc/apt/keyrings\n",
        "        !wget -qO- https://cli.github.com/packages/githubcli-archive-keyring.gpg | tee /etc/apt/keyrings/githubcli-archive-keyring.gpg > /dev/null\n",
        "        !chmod go+r /etc/apt/keyrings/githubcli-archive-keyring.gpg\n",
        "        !echo \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | tee /etc/apt/sources.list.d/github-cli.list > /dev/null\n",
        "        !apt-get update > /dev/null\n",
        "        !apt-get install gh > /dev/null\n",
        "        !gh auth login --hostname \"github.com\" --git-protocol https --with-token <<< {userdata.get(\"GH_TOKEN\")}\n",
        "        !git config --global user.name {userdata.get(\"GITHUB_USERNAME\")}\n",
        "        !git config --global user.email {userdata.get(\"GITHUB_EMAIL\")}\n",
        "        !git config --global pull.rebase false\n",
        "        !git config --global credential.helper store\n",
        "\n",
        "    # AUTHENTICATE: OpenAI\n",
        "    # https://www.kaggle.com/settings\n",
        "    if OpenAI:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "        !uv pip install --system --quiet openai\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "    # AUTHENTICATE: Hugging Face\n",
        "    # https://huggingface.co/docs/huggingface_hub/en/quick-start#authentication\n",
        "    if HuggingFace:\n",
        "        !uv pip install --system --quiet huggingface_hub[cli]\n",
        "        !huggingface-cli login --add-to-git-credential --token {userdata.get(\"HF_TOKEN\")} > /dev/null\n",
        "\n",
        "    # AUTHENTICATE: Kaggle\n",
        "    # https://www.kaggle.com/settings\n",
        "    if Kaggle:\n",
        "        os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "        os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")\n",
        "        !uv pip install --system --quiet kaggle\n",
        "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "        api = KaggleApi()\n",
        "        api.authenticate()\n",
        "\n",
        "    # MOUNT: Google Drive\n",
        "    import contextlib\n",
        "    with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
        "        import google.colab\n",
        "        google.colab.drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "    # SYMLINK: Google Drive folder to Files Pane (Top Level)\n",
        "    import pathlib\n",
        "    drive_path = pathlib.Path(\"/content/drive/MyDrive\")\n",
        "    colab_notebooks_path = drive_path / \"Colab Notebooks\"\n",
        "    project_path = colab_notebooks_path / GOOGLE_DRIVE_FOLDER\n",
        "    project_path.mkdir(parents=True, exist_ok=True)\n",
        "    shortcut = pathlib.Path(f\"/content/{GOOGLE_DRIVE_FOLDER}\")\n",
        "    shortcut.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if not shortcut.exists():\n",
        "        shortcut.symlink_to(project_path)\n",
        "\n",
        "    # REMOVE: Sample Folder\n",
        "    !rm -rf /content/sample_data\n",
        "\n",
        "    # ENSURE: apt packages\n",
        "    !apt-get install -qq \\\n",
        "        tree > /dev/null\n",
        "\n",
        "    # ENSURE: pip packages\n",
        "    !pip install --upgrade pip\n",
        "    !uv pip install --system --quiet \\\n",
        "        black[jupyter] \\\n",
        "        isort\n",
        "\n",
        "    # IMPORT: Python Libraries\n",
        "    import tqdm.notebook\n",
        "\n",
        "    # OUTPUTS\n",
        "    print(f\"SHORTCUT: {shortcut} --> {project_path}\")\n",
        "    return str(shortcut)\n",
        "\n",
        "SHORTCUT = bootstrap()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9-fNvAd9sbX",
        "outputId": "eecd9166-010b-411a-f12c-35fc0198df3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHORTCUT: /content/aai-511 --> /content/drive/MyDrive/Colab Notebooks/aai-511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!echo \"CPU Model: $(lscpu | grep 'Model name:' | cut -d ':' -f 2- | xargs)\"\n",
        "!echo \"CPU Sockets: $(lscpu | grep 'Socket(s):' | awk '{print $2}')\"\n",
        "!echo \"Cores per Socket: $(lscpu | grep 'Core(s) per socket:' | awk '{print $4}')\"\n",
        "!echo \"Threads per Core: $(lscpu | grep 'Thread(s) per core:' | awk '{print $4}')\"\n",
        "!echo \"Allocated RAM: $(free -h --si | awk '/Mem:/{print $2}')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYxpAtNSRoso",
        "outputId": "916f2589-0ab0-403a-a51d-905ebe00c835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "CPU Sockets: 2\n",
            "Cores per Socket: 24\n",
            "Threads per Core: 2\n",
            "Allocated RAM: 342G\n",
            "CPU times: user 34.7 ms, sys: 13.9 ms, total: 48.6 ms\n",
            "Wall time: 635 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# INSTALL: OS-LEVEL PACKAGES\n",
        "!apt-get install -qq --no-install-recommends \\\n",
        "    fluidsynth \\\n",
        "    fluid-soundfont-gm \\\n",
        "    graphviz \\\n",
        "    libfluidsynth3 \\\n",
        "    libgraphviz-dev \\\n",
        "\n",
        "# UNINSTALL: PYTHON PACKAGES\n",
        "!uv pip uninstall --system --quiet \\\n",
        "    bokeh \\\n",
        "    mkl\n",
        "\n",
        "# UPGRADE: PYTHON PACKAGES\n",
        "!uv pip install --system --quiet --upgrade \\\n",
        "    bokeh \\\n",
        "    datasets \\\n",
        "    pygraphviz \\\n",
        "    setuptools \\\n",
        "    wheel\n",
        "\n",
        "# INSTALL: PYTHON PACKAGES\n",
        "!uv pip install --system --quiet \\\n",
        "    autogluon \\\n",
        "    autokeras \\\n",
        "    black[jupyter] \\\n",
        "    cookiecutter-data-science \\\n",
        "    databricks-sdk \\\n",
        "    dvclive[all] \\\n",
        "    gensim \\\n",
        "    gradio \\\n",
        "    isort \\\n",
        "    kaggle \\\n",
        "    matplotlib \\\n",
        "    midi2audio \\\n",
        "    mido \\\n",
        "    mlflow \\\n",
        "    music21 \\\n",
        "    numpy==1.24.4 \\\n",
        "    pandas \\\n",
        "    pretty_midi \\\n",
        "    pyngrok \\\n",
        "    py_midicsv \\\n",
        "    scikit-learn \\\n",
        "    seaborn \\\n",
        "    shap\n"
      ],
      "metadata": {
        "id": "vcKREPflpNAG",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4a6d63-2a03-462e-9ee6-b767d1d49281"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.02 s, sys: 42.8 ms, total: 1.06 s\n",
            "Wall time: 17.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "print(\"Cloning Repository...\")\n",
        "!git clone https://github.com/aai511-groupX/project.git\n",
        "!cd /content/project && git submodule update --init --recursive\n",
        "!cd /content/project && git lfs pull\n",
        "\n",
        "REPO = pathlib.Path(f\"/content/project\")\n",
        "print(f\"REPO --> {REPO}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRXbtQXSTAPY",
        "outputId": "592a5fea-a713-48e5-80f2-bbf7ce62623b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning Repository...\n",
            "Cloning into 'project'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/38)\u001b[K\rremote: Counting objects:   5% (2/38)\u001b[K\rremote: Counting objects:   7% (3/38)\u001b[K\rremote: Counting objects:  10% (4/38)\u001b[K\rremote: Counting objects:  13% (5/38)\u001b[K\rremote: Counting objects:  15% (6/38)\u001b[K\rremote: Counting objects:  18% (7/38)\u001b[K\rremote: Counting objects:  21% (8/38)\u001b[K\rremote: Counting objects:  23% (9/38)\u001b[K\rremote: Counting objects:  26% (10/38)\u001b[K\rremote: Counting objects:  28% (11/38)\u001b[K\rremote: Counting objects:  31% (12/38)\u001b[K\rremote: Counting objects:  34% (13/38)\u001b[K\rremote: Counting objects:  36% (14/38)\u001b[K\rremote: Counting objects:  39% (15/38)\u001b[K\rremote: Counting objects:  42% (16/38)\u001b[K\rremote: Counting objects:  44% (17/38)\u001b[K\rremote: Counting objects:  47% (18/38)\u001b[K\rremote: Counting objects:  50% (19/38)\u001b[K\rremote: Counting objects:  52% (20/38)\u001b[K\rremote: Counting objects:  55% (21/38)\u001b[K\rremote: Counting objects:  57% (22/38)\u001b[K\rremote: Counting objects:  60% (23/38)\u001b[K\rremote: Counting objects:  63% (24/38)\u001b[K\rremote: Counting objects:  65% (25/38)\u001b[K\rremote: Counting objects:  68% (26/38)\u001b[K\rremote: Counting objects:  71% (27/38)\u001b[K\rremote: Counting objects:  73% (28/38)\u001b[K\rremote: Counting objects:  76% (29/38)\u001b[K\rremote: Counting objects:  78% (30/38)\u001b[K\rremote: Counting objects:  81% (31/38)\u001b[K\rremote: Counting objects:  84% (32/38)\u001b[K\rremote: Counting objects:  86% (33/38)\u001b[K\rremote: Counting objects:  89% (34/38)\u001b[K\rremote: Counting objects:  92% (35/38)\u001b[K\rremote: Counting objects:  94% (36/38)\u001b[K\rremote: Counting objects:  97% (37/38)\u001b[K\rremote: Counting objects: 100% (38/38)\u001b[K\rremote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects:   3% (1/28)\u001b[K\rremote: Compressing objects:   7% (2/28)\u001b[K\rremote: Compressing objects:  10% (3/28)\u001b[K\rremote: Compressing objects:  14% (4/28)\u001b[K\rremote: Compressing objects:  17% (5/28)\u001b[K\rremote: Compressing objects:  21% (6/28)\u001b[K\rremote: Compressing objects:  25% (7/28)\u001b[K\rremote: Compressing objects:  28% (8/28)\u001b[K\rremote: Compressing objects:  32% (9/28)\u001b[K\rremote: Compressing objects:  35% (10/28)\u001b[K\rremote: Compressing objects:  39% (11/28)\u001b[K\rremote: Compressing objects:  42% (12/28)\u001b[K\rremote: Compressing objects:  46% (13/28)\u001b[K\rremote: Compressing objects:  50% (14/28)\u001b[K\rremote: Compressing objects:  53% (15/28)\u001b[K\rremote: Compressing objects:  57% (16/28)\u001b[K\rremote: Compressing objects:  60% (17/28)\u001b[K\rremote: Compressing objects:  64% (18/28)\u001b[K\rremote: Compressing objects:  67% (19/28)\u001b[K\rremote: Compressing objects:  71% (20/28)\u001b[K\rremote: Compressing objects:  75% (21/28)\u001b[K\rremote: Compressing objects:  78% (22/28)\u001b[K\rremote: Compressing objects:  82% (23/28)\u001b[K\rremote: Compressing objects:  85% (24/28)\u001b[K\rremote: Compressing objects:  89% (25/28)\u001b[K\rremote: Compressing objects:  92% (26/28)\u001b[K\rremote: Compressing objects:  96% (27/28)\u001b[K\rremote: Compressing objects: 100% (28/28)\u001b[K\rremote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "Receiving objects:   2% (1/38)\rReceiving objects:   5% (2/38)\rReceiving objects:   7% (3/38)\rReceiving objects:  10% (4/38)\rReceiving objects:  13% (5/38)\rReceiving objects:  15% (6/38)\rReceiving objects:  18% (7/38)\rReceiving objects:  21% (8/38)\rReceiving objects:  23% (9/38)\rReceiving objects:  26% (10/38)\rReceiving objects:  28% (11/38)\rReceiving objects:  31% (12/38)\rReceiving objects:  34% (13/38)\rReceiving objects:  36% (14/38)\rReceiving objects:  39% (15/38)\rReceiving objects:  42% (16/38)\rReceiving objects:  44% (17/38)\rremote: Total 38 (delta 7), reused 33 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects:  47% (18/38)\rReceiving objects:  50% (19/38)\rReceiving objects:  52% (20/38)\rReceiving objects:  55% (21/38)\rReceiving objects:  57% (22/38)\rReceiving objects:  60% (23/38)\rReceiving objects:  63% (24/38)\rReceiving objects:  65% (25/38)\rReceiving objects:  68% (26/38)\rReceiving objects:  71% (27/38)\rReceiving objects:  73% (28/38)\rReceiving objects:  76% (29/38)\rReceiving objects:  78% (30/38)\rReceiving objects:  81% (31/38)\rReceiving objects:  84% (32/38)\rReceiving objects:  86% (33/38)\rReceiving objects:  89% (34/38)\rReceiving objects:  92% (35/38)\rReceiving objects:  94% (36/38)\rReceiving objects:  97% (37/38)\rReceiving objects: 100% (38/38)\rReceiving objects: 100% (38/38), 10.21 KiB | 2.04 MiB/s, done.\n",
            "Resolving deltas:   0% (0/7)\rResolving deltas:  14% (1/7)\rResolving deltas:  28% (2/7)\rResolving deltas:  42% (3/7)\rResolving deltas:  57% (4/7)\rResolving deltas:  71% (5/7)\rResolving deltas:  85% (6/7)\rResolving deltas: 100% (7/7)\rResolving deltas: 100% (7/7), done.\n",
            "Submodule 'data/raw/midi-classical-music' (https://huggingface.co/datasets/drengskapur/midi-classical-music) registered for path 'data/raw/midi-classical-music'\n",
            "Cloning into '/content/project/data/raw/midi-classical-music'...\n",
            "Submodule path 'data/raw/midi-classical-music': checked out '51e53dd002287106f69545946231a081be0ba773'\n",
            "REPO --> /content/project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINE: TARGET COMPOSERS\n",
        "COMPOSERS = [\n",
        "    \"bach\",\n",
        "    \"beethoven\",\n",
        "    \"chopin\",\n",
        "    \"mozart\"\n",
        "]\n",
        "\n",
        "# Move the data to the interim folder and rename files\n",
        "for composer in COMPOSERS:\n",
        "    !cp -r {REPO}/data/raw/midi-classical-music/{composer} {REPO}/data/interim"
      ],
      "metadata": {
        "id": "Qy8UaFBJwiAX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the data to the interim folder and rename files\n",
        "!mkdir -p {REPO}/data/interim/midi\n",
        "\n",
        "for composer in COMPOSERS:\n",
        "    interim_composer_dir = REPO / \"data\" / \"interim\" / composer\n",
        "    midi_dir = REPO / \"data\" / \"interim\" / \"midi\"\n",
        "\n",
        "    for filename in os.listdir(interim_composer_dir):\n",
        "        if filename.endswith(\".mid\"):\n",
        "            source_path = interim_composer_dir / filename\n",
        "            new_filename = f\"{composer}-{filename}\"\n",
        "            destination_path = midi_dir / new_filename\n",
        "            os.rename(source_path, destination_path)\n",
        "\n",
        "MIDI_FOLDER = f\"{REPO}/data/interim/midi\"\n",
        "print(f\"MIDI_FOLDER --> {MIDI_FOLDER}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEb18ndUx0Iq",
        "outputId": "a64c33a7-d3a9-4541-a318-8608657cc428"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MIDI_FOLDER --> /content/project/data/interim/midi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from music21 import midi\n",
        "import os\n",
        "from midi2audio import FluidSynth\n",
        "\n",
        "def play_midi(midi_directory, file_path):\n",
        "    full_path = os.path.join(midi_directory, file_path)\n",
        "    fs = FluidSynth()\n",
        "    wav_path = full_path.replace('.mid', '.wav')\n",
        "    fs.midi_to_audio(full_path, wav_path)\n",
        "    return wav_path\n",
        "\n",
        "def find_midi_files(directory):\n",
        "    midi_files = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".mid\"):\n",
        "                midi_files.append(os.path.join(root, file))\n",
        "    return midi_files\n",
        "\n",
        "midi_files = find_midi_files(MIDI_FOLDER)\n",
        "\n",
        "file_map = {os.path.basename(file): file for file in midi_files}\n",
        "dropdown = gr.Dropdown(choices=list(file_map.keys()), label=\"Select MIDI file\")\n",
        "\n",
        "def play_midi_from_filename(filename):\n",
        "    file_path = file_map[filename]\n",
        "    return play_midi(MIDI_FOLDER, file_path)\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=play_midi_from_filename,\n",
        "    inputs=dropdown,\n",
        "    outputs=gr.Audio(label=\"Play MIDI\"),\n",
        "    title=\"MIDI Player\",\n",
        "    analytics_enabled=False,\n",
        "    allow_flagging=None\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "0Aqu-hXf_C56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import py_midicsv as pm\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(\"Processing MIDI files...\")\n",
        "MIDI_FOLDER = f\"{REPO}/data/interim/midi\"\n",
        "CSV_FOLDER = f\"{REPO}/data/interim/csv\"\n",
        "\n",
        "if not os.path.exists(CSV_FOLDER):\n",
        "    os.makedirs(CSV_FOLDER)\n",
        "\n",
        "midi_files = [f for f in os.listdir(MIDI_FOLDER) if f.endswith(\".mid\")]\n",
        "\n",
        "def midi_to_csv(midi_path, csv_path):\n",
        "    try:\n",
        "        # Load the MIDI file and parse it into CSV format\n",
        "        csv_string_list = pm.midi_to_csv(midi_path)\n",
        "\n",
        "        # Write the CSV data to a file\n",
        "        with open(csv_path, \"w\") as f:\n",
        "            f.writelines(csv_string_list)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {midi_path}: {e}\")\n",
        "\n",
        "for filename in tqdm(midi_files, desc=\"Processing MIDI files\"):\n",
        "    midi_path = os.path.join(MIDI_FOLDER, filename)\n",
        "    csv_path = os.path.join(CSV_FOLDER, filename.replace(\".mid\", \".csv\"))\n",
        "    midi_to_csv(midi_path, csv_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "10f93ef2cec1444fbb097160acc47e4c",
            "20b0e57c2c364a0b947fadf31e61a479",
            "ae0d18afc3094c4495be7b747daa04cf",
            "3046bff62fbe414ebe1dd0531d0f33f2",
            "72441bd05477491d8bd6d140b648bc31",
            "83bda3bd0f4144e6a9048b9b329fcd9e",
            "33aa95eab8b444648b18c733371ddafa",
            "5b7e64c4fa4c4aafb53f1f81f5e6bf35",
            "7ab00dc71a9344418c54d3d90abf2942",
            "9b25a1ab16af4a919f62a7ab9b74558e",
            "052765d9ddb94f489370819529c82a1c"
          ]
        },
        "id": "V-YQKJ8mnL9x",
        "outputId": "7d388229-f3d2-49e2-c3cc-f045d8da4673"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing MIDI files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing MIDI files:   0%|          | 0/499 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10f93ef2cec1444fbb097160acc47e4c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "MIDI_FOLDER = f\"{REPO}/data/interim/midi\"\n",
        "CSV_FOLDER = f\"{REPO}/data/interim/csv\"\n",
        "\n",
        "def extract_features(midi_path):\n",
        "    try:\n",
        "        midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {midi_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Basic MIDI Information\n",
        "    total_duration = midi_data.get_end_time()\n",
        "    num_instruments = len(midi_data.instruments)\n",
        "\n",
        "    # Note-Level Features\n",
        "    notes = []\n",
        "    pitches = []\n",
        "    durations = []\n",
        "    velocities = []\n",
        "    harmony = []\n",
        "    polyphony = []\n",
        "\n",
        "    for instrument in midi_data.instruments:\n",
        "        instrument_notes = instrument.notes\n",
        "        notes.extend(instrument_notes)\n",
        "        pitches.extend([note.pitch for note in instrument_notes])\n",
        "        durations.extend([note.end - note.start for note in instrument_notes])\n",
        "        velocities.extend([note.velocity for note in instrument_notes])\n",
        "        harmony.extend([note.pitch for note in instrument_notes])\n",
        "        polyphony.extend([(note.start, note.end) for note in instrument_notes])\n",
        "\n",
        "    avg_pitch = np.mean(pitches) if pitches else 0\n",
        "    pitch_range = np.ptp(pitches) if pitches else 0\n",
        "    pitch_std = np.std(pitches) if pitches else 0\n",
        "    avg_duration = np.mean(durations) if durations else 0\n",
        "    duration_range = np.ptp(durations) if durations else 0\n",
        "    duration_std = np.std(durations) if durations else 0\n",
        "    avg_velocity = np.mean(velocities) if velocities else 0\n",
        "    velocity_variance = np.var(velocities) if velocities else 0\n",
        "\n",
        "    # Time Signature and Key\n",
        "    time_signature = midi_data.time_signature_changes[0].numerator if midi_data.time_signature_changes else 4\n",
        "    try:\n",
        "        key_signature = midi_data.key_signature_changes[0] if midi_data.key_signature_changes else None\n",
        "        if key_signature:\n",
        "            key = key_signature.key_number % 12\n",
        "            mode = 'major' if key_signature.key_number < 12 else 'minor'\n",
        "        else:\n",
        "            key = 0\n",
        "            mode = 'major'\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing key signature for {midi_path}: {e}\")\n",
        "        key = 0\n",
        "        mode = 'major'\n",
        "\n",
        "    # Harmonic Features\n",
        "    harmony_complexity = len(set(harmony))\n",
        "\n",
        "    # Rhythmic Features\n",
        "    note_density = len(pitches) / total_duration if total_duration > 0 else 0\n",
        "\n",
        "    # Dynamic Features\n",
        "    dynamic_range = np.ptp(velocities) if velocities else 0\n",
        "\n",
        "    # Articulation Features\n",
        "    staccato_ratio = sum(1 for d in durations if d < 0.1) / len(durations) if durations else 0\n",
        "    legato_ratio = sum(1 for d in durations if d > 0.5) / len(durations) if durations else 0\n",
        "\n",
        "    # Polyphony Features\n",
        "    polyphony_density = np.mean([end - start for start, end in polyphony]) if polyphony else 0\n",
        "\n",
        "    # Tempo Features\n",
        "    tempo_changes = midi_data.get_tempo_changes()[1]\n",
        "    tempo_variability = np.std(tempo_changes) if len(tempo_changes) > 1 else 0\n",
        "    avg_tempo = np.mean(tempo_changes) if len(tempo_changes) > 0 else 0\n",
        "\n",
        "    # Orchestration Features\n",
        "    instrument_families = [instrument.program // 8 for instrument in midi_data.instruments]\n",
        "    instrument_diversity = len(set(instrument_families))\n",
        "\n",
        "    # Expressive Features\n",
        "    articulation_variability = np.std([note.end - note.start for note in notes]) if notes else 0\n",
        "    dynamic_variability = np.std(velocities) if velocities else 0\n",
        "\n",
        "    # Pitch Class Features\n",
        "    pitch_classes = [note.pitch % 12 for note in notes]\n",
        "    pitch_class_histogram = np.histogram(pitch_classes, bins=12, range=(0, 12))[0]\n",
        "\n",
        "    # Interval Features\n",
        "    intervals = np.diff(pitches) if len(pitches) > 1 else [0]\n",
        "    interval_histogram = np.histogram(intervals, bins=12, range=(-6, 6))[0]\n",
        "\n",
        "    # Additional Features\n",
        "    pitch_entropy = -np.sum((np.histogram(pitches, bins=128, range=(0, 128))[0] / len(pitches)) * np.log2(np.histogram(pitches, bins=128, range=(0, 128))[0] / len(pitches) + 1e-9)) if pitches else 0\n",
        "    duration_entropy = -np.sum((np.histogram(durations, bins=100)[0] / len(durations)) * np.log2(np.histogram(durations, bins=100)[0] / len(durations) + 1e-9)) if durations else 0\n",
        "    velocity_entropy = -np.sum((np.histogram(velocities, bins=128, range=(0, 128))[0] / len(velocities)) * np.log2(np.histogram(velocities, bins=128, range=(0, 128))[0] / len(velocities) + 1e-9)) if velocities else 0\n",
        "    chord_entropy = -np.sum((np.histogram(harmony, bins=128, range=(0, 128))[0] / len(harmony)) * np.log2(np.histogram(harmony, bins=128, range=(0, 128))[0] / len(harmony) + 1e-9)) if harmony else 0\n",
        "    key_changes = len(midi_data.key_signature_changes)\n",
        "    tempo_changes_count = len(tempo_changes)\n",
        "\n",
        "    # New features\n",
        "    pitch_skewness = skew(pitches) if pitches else 0\n",
        "    pitch_kurtosis = kurtosis(pitches) if pitches else 0\n",
        "\n",
        "    # Melodic contour (simplified)\n",
        "    melodic_contour = np.diff(pitches) if len(pitches) > 1 else [0]\n",
        "    contour_direction = np.sum(np.sign(melodic_contour))\n",
        "\n",
        "    # Rhythmic complexity (simplified)\n",
        "    ioi = np.diff([note.start for note in notes]) if len(notes) > 1 else [0]\n",
        "    rhythmic_complexity = np.std(ioi) if len(ioi) > 0 else 0\n",
        "\n",
        "    features = {\n",
        "        'duration': total_duration,\n",
        "        'num_instruments': num_instruments,\n",
        "        'notes': len(notes),\n",
        "        'avg_pitch': avg_pitch,\n",
        "        'pitch_range': pitch_range,\n",
        "        'pitch_std': pitch_std,\n",
        "        'avg_duration': avg_duration,\n",
        "        'duration_range': duration_range,\n",
        "        'duration_std': duration_std,\n",
        "        'time_signature': time_signature,\n",
        "        'key': key,\n",
        "        'mode': mode,\n",
        "        'harmony_complexity': harmony_complexity,\n",
        "        'note_density': note_density,\n",
        "        'avg_velocity': avg_velocity,\n",
        "        'velocity_variance': velocity_variance,\n",
        "        'dynamic_range': dynamic_range,\n",
        "        'staccato_ratio': staccato_ratio,\n",
        "        'legato_ratio': legato_ratio,\n",
        "        'polyphony_density': polyphony_density,\n",
        "        'tempo_variability': tempo_variability,\n",
        "        'avg_tempo': avg_tempo,\n",
        "        'instrument_diversity': instrument_diversity,\n",
        "        'articulation_variability': articulation_variability,\n",
        "        'dynamic_variability': dynamic_variability,\n",
        "        'pitch_class_histogram': pitch_class_histogram.tolist(),\n",
        "        'interval_histogram': interval_histogram.tolist(),\n",
        "        'pitch_entropy': pitch_entropy,\n",
        "        'duration_entropy': duration_entropy,\n",
        "        'velocity_entropy': velocity_entropy,\n",
        "        'chord_entropy': chord_entropy,\n",
        "        'key_changes': key_changes,\n",
        "        'tempo_changes_count': tempo_changes_count,\n",
        "        'pitch_skewness': pitch_skewness,\n",
        "        'pitch_kurtosis': pitch_kurtosis,\n",
        "        'contour_direction': contour_direction,\n",
        "        'rhythmic_complexity': rhythmic_complexity,\n",
        "    }\n",
        "\n",
        "    return features\n",
        "\n",
        "def process_file(filename):\n",
        "    midi_path = os.path.join(MIDI_FOLDER, filename)\n",
        "    try:\n",
        "        features = extract_features(midi_path)\n",
        "        if features is not None:\n",
        "            features['filename'] = filename\n",
        "             # Assuming filename format is composer-filename.mid\n",
        "            features['composer'] = filename.split('-')[0]\n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {filename}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Main execution\n",
        "midi_files = [f for f in os.listdir(MIDI_FOLDER) if f.endswith(\".mid\")]\n",
        "\n",
        "# Process files\n",
        "all_features = []\n",
        "for filename in tqdm(midi_files, desc=\"Extracting features\"):\n",
        "    features = process_file(filename)\n",
        "    if features is not None:\n",
        "        all_features.append(features)\n",
        "\n",
        "# Convert to DataFrame\n",
        "features_df = pd.DataFrame(all_features)\n",
        "\n",
        "# Save to CSV\n",
        "csv_path = os.path.join(CSV_FOLDER, 'midi_features.csv')\n",
        "features_df.to_csv(csv_path, index=False)\n",
        "print(f\"Features saved to {csv_path}\")"
      ],
      "metadata": {
        "id": "s_248dqAshUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fabba573-3186-41a3-e031-fe7aec3b03a6"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  55%|█████▍    | 274/499 [01:16<01:16,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /content/project/data/interim/midi/beethoven-anhang_14_3.mid: Could not decode key with 3 flats and mode 255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 499/499 [02:13<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to /content/project/data/interim/csv/midi_features.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import ast\n",
        "\n",
        "# Load the features\n",
        "csv_path = os.path.join(CSV_FOLDER, 'midi_features.csv')\n",
        "features_df = pd.read_csv(csv_path)\n",
        "\n",
        "# Encode categorical features\n",
        "label_encoder = LabelEncoder()\n",
        "features_df['composer'] = label_encoder.fit_transform(features_df['composer'])\n",
        "features_df['mode'] = label_encoder.fit_transform(features_df['mode'])\n",
        "\n",
        "# Convert list-like strings to numerical arrays\n",
        "features_df['pitch_class_histogram'] = features_df['pitch_class_histogram'].apply(ast.literal_eval)\n",
        "features_df['interval_histogram'] = features_df['interval_histogram'].apply(ast.literal_eval)\n",
        "\n",
        "# Flatten list-like columns\n",
        "pitch_class_histogram_df = pd.DataFrame(features_df['pitch_class_histogram'].tolist(), index=features_df.index)\n",
        "interval_histogram_df = pd.DataFrame(features_df['interval_histogram'].tolist(), index=features_df.index)\n",
        "\n",
        "# Rename columns to avoid conflicts\n",
        "pitch_class_histogram_df.columns = [f'pitch_class_histogram_{i}' for i in range(pitch_class_histogram_df.shape[1])]\n",
        "interval_histogram_df.columns = [f'interval_histogram_{i}' for i in range(interval_histogram_df.shape[1])]\n",
        "\n",
        "# Concatenate the flattened columns back to the original DataFrame\n",
        "features_df = pd.concat([features_df, pitch_class_histogram_df, interval_histogram_df], axis=1)\n",
        "features_df.drop(columns=['pitch_class_histogram', 'interval_histogram', 'filename'], inplace=True)\n",
        "\n",
        "# Normalize numerical features\n",
        "numerical_features = features_df.select_dtypes(include=[np.number]).columns\n",
        "scaler = StandardScaler()\n",
        "features_df[numerical_features] = scaler.fit_transform(features_df[numerical_features])\n",
        "\n",
        "# Ensure all features are numeric\n",
        "for col in features_df.columns:\n",
        "    if features_df[col].dtype == 'object':\n",
        "        features_df[col] = features_df[col].apply(lambda x: np.nan if x == '' else x).astype(float)\n",
        "\n",
        "# Drop rows with NaN values (if any)\n",
        "features_df.dropna(inplace=True)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = features_df.drop(columns=['composer'])\n",
        "y = features_df['composer']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure that the labels are within the valid range\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y_train = np.clip(y_train, 0, num_classes - 1)\n",
        "y_test = np.clip(y_test, 0, num_classes - 1)"
      ],
      "metadata": {
        "id": "hCu1zulOYMy2"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
        "\n",
        "# Define the LSTM model\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(64, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "# Reshape the data for LSTM\n",
        "X_train_lstm = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_lstm = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Create and compile the LSTM model\n",
        "lstm_model = create_lstm_model((X_train_lstm.shape[1], 1))\n",
        "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, validation_data=(X_test_lstm, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LHye3VUcx6h",
        "outputId": "a45c61ef-9b67-4440-860e-c03fb62fc80b"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 278ms/step - accuracy: 0.5522 - loss: 0.5939 - val_accuracy: 0.5000 - val_loss: 0.6067\n",
            "Epoch 2/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 376ms/step - accuracy: 0.5668 - loss: 0.5199 - val_accuracy: 0.5000 - val_loss: 0.5142\n",
            "Epoch 3/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.5668 - loss: 0.4588 - val_accuracy: 0.5000 - val_loss: 0.5193\n",
            "Epoch 4/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 376ms/step - accuracy: 0.5668 - loss: 0.4486 - val_accuracy: 0.5000 - val_loss: 0.5165\n",
            "Epoch 5/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.5668 - loss: 0.4516 - val_accuracy: 0.5000 - val_loss: 0.5141\n",
            "Epoch 6/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 370ms/step - accuracy: 0.5668 - loss: 0.4602 - val_accuracy: 0.5000 - val_loss: 0.5106\n",
            "Epoch 7/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.5668 - loss: 0.4556 - val_accuracy: 0.5000 - val_loss: 0.5082\n",
            "Epoch 8/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5668 - loss: 0.4453 - val_accuracy: 0.5000 - val_loss: 0.5039\n",
            "Epoch 9/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 379ms/step - accuracy: 0.5668 - loss: 0.4577 - val_accuracy: 0.5000 - val_loss: 0.4969\n",
            "Epoch 10/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.5668 - loss: 0.4378 - val_accuracy: 0.5000 - val_loss: 0.4935\n",
            "Epoch 11/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 299ms/step - accuracy: 0.5668 - loss: 0.4729 - val_accuracy: 0.5000 - val_loss: 0.5073\n",
            "Epoch 12/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 289ms/step - accuracy: 0.5668 - loss: 0.4498 - val_accuracy: 0.5000 - val_loss: 0.4956\n",
            "Epoch 13/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.5668 - loss: 0.4394 - val_accuracy: 0.5000 - val_loss: 0.4861\n",
            "Epoch 14/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 293ms/step - accuracy: 0.5668 - loss: 0.4344 - val_accuracy: 0.5000 - val_loss: 0.4757\n",
            "Epoch 15/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 301ms/step - accuracy: 0.5668 - loss: 0.4418 - val_accuracy: 0.5000 - val_loss: 0.4809\n",
            "Epoch 16/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.5668 - loss: 0.4345 - val_accuracy: 0.5000 - val_loss: 0.4572\n",
            "Epoch 17/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5580 - loss: 0.4314 - val_accuracy: 0.5100 - val_loss: 0.4521\n",
            "Epoch 18/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 292ms/step - accuracy: 0.5618 - loss: 0.4557 - val_accuracy: 0.5100 - val_loss: 0.4435\n",
            "Epoch 19/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 287ms/step - accuracy: 0.5750 - loss: 0.4483 - val_accuracy: 0.4800 - val_loss: 0.4755\n",
            "Epoch 20/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.5545 - loss: 0.4691 - val_accuracy: 0.5000 - val_loss: 0.4919\n",
            "Epoch 21/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 362ms/step - accuracy: 0.5668 - loss: 0.4475 - val_accuracy: 0.5000 - val_loss: 0.4521\n",
            "Epoch 22/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5668 - loss: 0.4403 - val_accuracy: 0.5000 - val_loss: 0.4364\n",
            "Epoch 23/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.5668 - loss: 0.4478 - val_accuracy: 0.5000 - val_loss: 0.4370\n",
            "Epoch 24/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 373ms/step - accuracy: 0.5668 - loss: 0.4456 - val_accuracy: 0.5000 - val_loss: 0.4289\n",
            "Epoch 25/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5663 - loss: 0.4201 - val_accuracy: 0.5000 - val_loss: 0.4142\n",
            "Epoch 26/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 343ms/step - accuracy: 0.5595 - loss: 0.4384 - val_accuracy: 0.5000 - val_loss: 0.4466\n",
            "Epoch 27/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5668 - loss: 0.4264 - val_accuracy: 0.5000 - val_loss: 0.4145\n",
            "Epoch 28/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5707 - loss: 0.4254 - val_accuracy: 0.5000 - val_loss: 0.4068\n",
            "Epoch 29/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350ms/step - accuracy: 0.5613 - loss: 0.4055 - val_accuracy: 0.5100 - val_loss: 0.4088\n",
            "Epoch 30/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5685 - loss: 0.4277 - val_accuracy: 0.5000 - val_loss: 0.4198\n",
            "Epoch 31/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.5753 - loss: 0.3986 - val_accuracy: 0.5400 - val_loss: 0.4084\n",
            "Epoch 32/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.5608 - loss: 0.4010 - val_accuracy: 0.5500 - val_loss: 0.4013\n",
            "Epoch 33/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 216ms/step - accuracy: 0.5422 - loss: 0.4434 - val_accuracy: 0.5000 - val_loss: 0.4288\n",
            "Epoch 34/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.5505 - loss: 0.4275 - val_accuracy: 0.5000 - val_loss: 0.4124\n",
            "Epoch 35/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.5675 - loss: 0.4340 - val_accuracy: 0.5000 - val_loss: 0.4152\n",
            "Epoch 36/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 376ms/step - accuracy: 0.5723 - loss: 0.3870 - val_accuracy: 0.5100 - val_loss: 0.4000\n",
            "Epoch 37/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5711 - loss: 0.3870 - val_accuracy: 0.5400 - val_loss: 0.4087\n",
            "Epoch 38/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354ms/step - accuracy: 0.5804 - loss: 0.3786 - val_accuracy: 0.5400 - val_loss: 0.4236\n",
            "Epoch 39/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.5816 - loss: 0.3717 - val_accuracy: 0.5700 - val_loss: 0.3657\n",
            "Epoch 40/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 280ms/step - accuracy: 0.5878 - loss: 0.3811 - val_accuracy: 0.5500 - val_loss: 0.3874\n",
            "Epoch 41/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - accuracy: 0.5873 - loss: 0.3672 - val_accuracy: 0.5900 - val_loss: 0.3787\n",
            "Epoch 42/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.5843 - loss: 0.3674 - val_accuracy: 0.5800 - val_loss: 0.3717\n",
            "Epoch 43/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.5855 - loss: 0.3753 - val_accuracy: 0.5500 - val_loss: 0.3977\n",
            "Epoch 44/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - accuracy: 0.5944 - loss: 0.3846 - val_accuracy: 0.5600 - val_loss: 0.3657\n",
            "Epoch 45/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - accuracy: 0.5749 - loss: 0.3879 - val_accuracy: 0.5700 - val_loss: 0.3723\n",
            "Epoch 46/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.5884 - loss: 0.3784 - val_accuracy: 0.5600 - val_loss: 0.3870\n",
            "Epoch 47/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.5850 - loss: 0.4092 - val_accuracy: 0.5300 - val_loss: 0.4571\n",
            "Epoch 48/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 297ms/step - accuracy: 0.5707 - loss: 0.4143 - val_accuracy: 0.5400 - val_loss: 0.3856\n",
            "Epoch 49/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - accuracy: 0.5867 - loss: 0.3653 - val_accuracy: 0.5400 - val_loss: 0.3705\n",
            "Epoch 50/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 304ms/step - accuracy: 0.5928 - loss: 0.3539 - val_accuracy: 0.5800 - val_loss: 0.3569\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cd77c4905b0>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "# Define the CNN model\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "# Reshape the data for CNN\n",
        "X_train_cnn = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_cnn = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Create and compile the CNN model\n",
        "cnn_model = create_cnn_model((X_train_cnn.shape[1], 1))\n",
        "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN model\n",
        "cnn_model.fit(X_train_cnn, y_train, epochs=50, batch_size=32, validation_data=(X_test_cnn, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oedbCuuiiNYR",
        "outputId": "8a19bd0c-307d-4588-8ab1-c9a7a19d43e9"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5595 - loss: 0.4963 - val_accuracy: 0.5000 - val_loss: 0.4832\n",
            "Epoch 2/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5668 - loss: 0.4343 - val_accuracy: 0.5000 - val_loss: 0.4564\n",
            "Epoch 3/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5668 - loss: 0.4271 - val_accuracy: 0.5000 - val_loss: 0.4338\n",
            "Epoch 4/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5668 - loss: 0.4093 - val_accuracy: 0.5000 - val_loss: 0.4121\n",
            "Epoch 5/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.5668 - loss: 0.3869 - val_accuracy: 0.5000 - val_loss: 0.3885\n",
            "Epoch 6/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5767 - loss: 0.3616 - val_accuracy: 0.5100 - val_loss: 0.3683\n",
            "Epoch 7/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5809 - loss: 0.3320 - val_accuracy: 0.5600 - val_loss: 0.3570\n",
            "Epoch 8/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5974 - loss: 0.3213 - val_accuracy: 0.5600 - val_loss: 0.3517\n",
            "Epoch 9/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5869 - loss: 0.3128 - val_accuracy: 0.5700 - val_loss: 0.3492\n",
            "Epoch 10/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.6298 - loss: 0.3013 - val_accuracy: 0.5600 - val_loss: 0.3547\n",
            "Epoch 11/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.5909 - loss: 0.3103 - val_accuracy: 0.5500 - val_loss: 0.3480\n",
            "Epoch 12/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6270 - loss: 0.3010 - val_accuracy: 0.5600 - val_loss: 0.3398\n",
            "Epoch 13/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6180 - loss: 0.2803 - val_accuracy: 0.5700 - val_loss: 0.3389\n",
            "Epoch 14/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6234 - loss: 0.2551 - val_accuracy: 0.5800 - val_loss: 0.3297\n",
            "Epoch 15/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6475 - loss: 0.2322 - val_accuracy: 0.5700 - val_loss: 0.3314\n",
            "Epoch 16/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6308 - loss: 0.2143 - val_accuracy: 0.5800 - val_loss: 0.3392\n",
            "Epoch 17/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6352 - loss: 0.2227 - val_accuracy: 0.5700 - val_loss: 0.3364\n",
            "Epoch 18/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.6447 - loss: 0.2264 - val_accuracy: 0.5600 - val_loss: 0.3275\n",
            "Epoch 19/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6490 - loss: 0.2253 - val_accuracy: 0.5800 - val_loss: 0.3308\n",
            "Epoch 20/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6558 - loss: 0.1845 - val_accuracy: 0.5600 - val_loss: 0.3220\n",
            "Epoch 21/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6468 - loss: 0.1897 - val_accuracy: 0.5700 - val_loss: 0.3288\n",
            "Epoch 22/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6442 - loss: 0.2017 - val_accuracy: 0.5800 - val_loss: 0.3430\n",
            "Epoch 23/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6792 - loss: 0.1742 - val_accuracy: 0.5900 - val_loss: 0.3285\n",
            "Epoch 24/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6710 - loss: 0.1671 - val_accuracy: 0.6000 - val_loss: 0.3433\n",
            "Epoch 25/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6554 - loss: 0.1504 - val_accuracy: 0.5700 - val_loss: 0.3572\n",
            "Epoch 26/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6823 - loss: 0.1401 - val_accuracy: 0.6100 - val_loss: 0.3403\n",
            "Epoch 27/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6795 - loss: 0.1462 - val_accuracy: 0.6100 - val_loss: 0.3583\n",
            "Epoch 28/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6762 - loss: 0.1379 - val_accuracy: 0.5800 - val_loss: 0.3676\n",
            "Epoch 29/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6974 - loss: 0.1218 - val_accuracy: 0.5900 - val_loss: 0.3254\n",
            "Epoch 30/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6830 - loss: 0.1425 - val_accuracy: 0.6000 - val_loss: 0.3385\n",
            "Epoch 31/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6991 - loss: 0.1250 - val_accuracy: 0.5900 - val_loss: 0.3637\n",
            "Epoch 32/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6932 - loss: 0.1163 - val_accuracy: 0.6200 - val_loss: 0.3378\n",
            "Epoch 33/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6898 - loss: 0.1255 - val_accuracy: 0.5800 - val_loss: 0.3804\n",
            "Epoch 34/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.6923 - loss: 0.1265 - val_accuracy: 0.6000 - val_loss: 0.3589\n",
            "Epoch 35/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.6914 - loss: 0.1093 - val_accuracy: 0.5800 - val_loss: 0.3621\n",
            "Epoch 36/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.7145 - loss: 0.0783 - val_accuracy: 0.5900 - val_loss: 0.3573\n",
            "Epoch 37/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7079 - loss: 0.0985 - val_accuracy: 0.5900 - val_loss: 0.3508\n",
            "Epoch 38/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6984 - loss: 0.0984 - val_accuracy: 0.6000 - val_loss: 0.3502\n",
            "Epoch 39/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7005 - loss: 0.1152 - val_accuracy: 0.5900 - val_loss: 0.3832\n",
            "Epoch 40/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7137 - loss: 0.0826 - val_accuracy: 0.6100 - val_loss: 0.3691\n",
            "Epoch 41/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6969 - loss: 0.0788 - val_accuracy: 0.5900 - val_loss: 0.3859\n",
            "Epoch 42/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7078 - loss: 0.0754 - val_accuracy: 0.5900 - val_loss: 0.3736\n",
            "Epoch 43/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.7221 - loss: 0.0664 - val_accuracy: 0.5900 - val_loss: 0.4001\n",
            "Epoch 44/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.7169 - loss: 0.0652 - val_accuracy: 0.6100 - val_loss: 0.4202\n",
            "Epoch 45/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7003 - loss: 0.0899 - val_accuracy: 0.5900 - val_loss: 0.4063\n",
            "Epoch 46/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7182 - loss: 0.0675 - val_accuracy: 0.5900 - val_loss: 0.3976\n",
            "Epoch 47/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6847 - loss: 0.1032 - val_accuracy: 0.5800 - val_loss: 0.4530\n",
            "Epoch 48/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7202 - loss: 0.0948 - val_accuracy: 0.6000 - val_loss: 0.4345\n",
            "Epoch 49/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7017 - loss: 0.0822 - val_accuracy: 0.6100 - val_loss: 0.3850\n",
            "Epoch 50/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7140 - loss: 0.0660 - val_accuracy: 0.6000 - val_loss: 0.3890\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cd71c50b0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the LSTM model\n",
        "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test_lstm, y_test)\n",
        "print(f\"LSTM Model Accuracy: {lstm_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yESiutM3roy5",
        "outputId": "26401228-6744-44a0-cd08-3cc4c6b4385f"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5830 - loss: 0.3769\n",
            "LSTM Model Accuracy: 58.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the CNN model\n",
        "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test_cnn, y_test)\n",
        "print(f\"CNN Model Accuracy: {cnn_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byl3CVS0rxyA",
        "outputId": "62e9ee7f-b0a7-4ad8-a403-9670473d5d43"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3994 \n",
            "CNN Model Accuracy: 60.00%\n"
          ]
        }
      ]
    }
  ]
}